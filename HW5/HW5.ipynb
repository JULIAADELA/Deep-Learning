{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "a824b075",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision\n",
    "import torchvision.transforms as transforms\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b6cc72f0",
   "metadata": {},
   "source": [
    "# Bài 1:\n",
    "Code from scratch hàm transposed convolution"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "31d99340",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 0.,  0.,  1.],\n",
       "        [ 0.,  4.,  6.],\n",
       "        [ 4., 12.,  9.]])"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "def trans_conv(X, K):\n",
    "    h, w = K.shape\n",
    "    Y = torch.zeros((X.shape[0] + h - 1, X.shape[1] + w - 1))\n",
    "    for i in range(X.shape[0]):\n",
    "        for j in range(X.shape[1]):\n",
    "            Y[i: i + h, j: j + w] += X[i, j] * K\n",
    "    return Y\n",
    "\n",
    "X = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "K = torch.tensor([[0.0, 1.0], [2.0, 3.0]])\n",
    "trans_conv(X, K)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "4babfd62",
   "metadata": {},
   "source": [
    "# Bài 2:\n",
    "Cho dataset cifar-10\n",
    "\n",
    "1.Cho noise cho dataset được sample từ normal distribution (mean = 0, variance = 0.1)\\\n",
    "2.Dùng cấu trúc autoencoder để denoise lại bức ảnh về như ban đầu\\\n",
    "3.Visualize ảnh ban đầu, ảnh được thêm noise, và ảnh sau khi denoise."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "a7989300",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Files already downloaded and verified\n"
     ]
    }
   ],
   "source": [
    "# Tải CIFAR-10 dataset và chuyển đổi dữ liệu thành tensor\n",
    "transform = transforms.Compose([transforms.ToTensor()])\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=4, shuffle=True, num_workers=2)\n",
    "\n",
    "# Hàm thêm nhiễu Gaussian\n",
    "def add_noise(img, mean=0, std=0.1):\n",
    "    noise = torch.randn(img.size()) * std + mean\n",
    "    noisy_img = img + noise\n",
    "    return noisy_img.clamp(0, 1)\n",
    "\n",
    "# Lấy một batch ảnh và thêm nhiễu\n",
    "dataiter = iter(trainloader)\n",
    "images, _ = next(dataiter)\n",
    "noisy_images = add_noise(images)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "c502c222",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Mô hình autoencoder\n",
    "class Autoencoder(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(Autoencoder, self).__init__()\n",
    "        self.encoder = nn.Sequential(\n",
    "            nn.Conv2d(3, 32, 3, padding=1),\n",
    "            nn.ReLU(),\n",
    "            nn.MaxPool2d(2, 2)\n",
    "        )\n",
    "        self.decoder = nn.Sequential(\n",
    "            nn.ConvTranspose2d(32, 3, 2, stride=2)\n",
    "        )\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.encoder(x)\n",
    "        x = self.decoder(x)\n",
    "        return x\n",
    "\n",
    "autoencoder = Autoencoder()\n",
    "\n",
    "# Hàm mất mát và tối ưu hóa\n",
    "criterion = nn.MSELoss()\n",
    "optimizer = optim.Adam(autoencoder.parameters(), lr=0.001)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "efdc8b19",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Loss: 0.0027\n",
      "Epoch [2/10], Loss: 0.0024\n",
      "Epoch [3/10], Loss: 0.0029\n",
      "Epoch [4/10], Loss: 0.0025\n",
      "Epoch [5/10], Loss: 0.0026\n",
      "Epoch [6/10], Loss: 0.0023\n",
      "Epoch [7/10], Loss: 0.0029\n",
      "Epoch [8/10], Loss: 0.0018\n",
      "Epoch [9/10], Loss: 0.0027\n",
      "Epoch [10/10], Loss: 0.0026\n"
     ]
    }
   ],
   "source": [
    "num_epochs = 10\n",
    "\n",
    "for epoch in range(num_epochs):\n",
    "    for data in trainloader:\n",
    "        inputs, _ = data\n",
    "        noisy_inputs = add_noise(inputs)\n",
    "        optimizer.zero_grad()\n",
    "        outputs = autoencoder(noisy_inputs)\n",
    "        loss = criterion(outputs, inputs)\n",
    "        loss.backward()\n",
    "        optimizer.step()\n",
    "\n",
    "    # In ra mất mát trung bình sau mỗi epoch\n",
    "    print('Epoch [{}/{}], Loss: {:.4f}'.format(epoch+1, num_epochs, loss.item()))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3f317d9b",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'trainloader' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[1], line 12\u001b[0m\n\u001b[0;32m      9\u001b[0m     plt\u001b[38;5;241m.\u001b[39mtitle(title)\n\u001b[0;32m     10\u001b[0m     plt\u001b[38;5;241m.\u001b[39mshow()\n\u001b[1;32m---> 12\u001b[0m dataiter \u001b[38;5;241m=\u001b[39m \u001b[38;5;28miter\u001b[39m(\u001b[43mtrainloader\u001b[49m)\n\u001b[0;32m     13\u001b[0m images, _ \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mnext\u001b[39m(dataiter)\n\u001b[0;32m     14\u001b[0m noisy_images \u001b[38;5;241m=\u001b[39m add_noise(images)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'trainloader' is not defined"
     ]
    }
   ],
   "source": [
    "# Visualize ảnh ban đầu, ảnh nhiễu, và ảnh sau khi denoise\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "def imshow(img, title):\n",
    "    img = img / 2 + 0.5\n",
    "    npimg = img.numpy()\n",
    "    plt.figure(figsize=(8, 4))\n",
    "    plt.imshow(np.transpose(npimg, (1, 2, 0)))\n",
    "    plt.title(title)\n",
    "    plt.show()\n",
    "\n",
    "dataiter = iter(trainloader)\n",
    "images, _ = next(dataiter)\n",
    "noisy_images = add_noise(images)\n",
    "\n",
    "# Lấy một batch ảnh và thêm nhiễu\n",
    "with torch.no_grad():\n",
    "    denoised_images = autoencoder(noisy_images)\n",
    "\n",
    "imshow(torchvision.utils.make_grid(images), \"Original Images\")\n",
    "imshow(torchvision.utils.make_grid(noisy_images), \"Noisy Images\")\n",
    "imshow(torchvision.utils.make_grid(denoised_images), \"Denoised Images\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "1e439e27",
   "metadata": {},
   "source": [
    "# Bài 3:\n",
    "Cho dataset cifar-10\n",
    "\n",
    "1.Giảm chiều dữ liệu về dạng 2d của 1 ảnh bất kỳ bằng 2 phương pháp: PCA và convolution AE.\\\n",
    "2.Visualize và so sánh 2 phương pháp"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "807a3361",
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'transforms' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[1;32mIn[2], line 1\u001b[0m\n\u001b[1;32m----> 1\u001b[0m transform \u001b[38;5;241m=\u001b[39m \u001b[43mtransforms\u001b[49m\u001b[38;5;241m.\u001b[39mCompose([\n\u001b[0;32m      2\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mToTensor(),\n\u001b[0;32m      3\u001b[0m     transforms\u001b[38;5;241m.\u001b[39mNormalize((\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m), (\u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m, \u001b[38;5;241m0.5\u001b[39m))\n\u001b[0;32m      4\u001b[0m ])\n\u001b[0;32m      6\u001b[0m batch_size \u001b[38;5;241m=\u001b[39m \u001b[38;5;241m64\u001b[39m\n\u001b[0;32m      8\u001b[0m trainset \u001b[38;5;241m=\u001b[39m torchvision\u001b[38;5;241m.\u001b[39mdatasets\u001b[38;5;241m.\u001b[39mCIFAR10(root\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124m./data\u001b[39m\u001b[38;5;124m'\u001b[39m, train\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, download\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, transform\u001b[38;5;241m=\u001b[39mtransform)\n",
      "\u001b[1;31mNameError\u001b[0m: name 'transforms' is not defined"
     ]
    }
   ],
   "source": [
    "transform = transforms.Compose([\n",
    "    transforms.ToTensor(),\n",
    "    transforms.Normalize((0.5, 0.5, 0.5), (0.5, 0.5, 0.5))\n",
    "])\n",
    "\n",
    "batch_size = 64\n",
    "\n",
    "trainset = torchvision.datasets.CIFAR10(root='./data', train=True, download=True, transform=transform)\n",
    "trainloader = torch.utils.data.DataLoader(trainset, batch_size=batch_size, shuffle=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7728d857",
   "metadata": {},
   "source": [
    "## Giảm chiều dữ liệu bằng PCA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ba886c66",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "\n",
    "# Lấy một batch dữ liệu CIFAR-10\n",
    "dataiter = iter(trainloader)\n",
    "images, labels = next(dataiter)\n",
    "images = images.view(images.size(0), -1)  # Đưa dữ liệu về dạng vector\n",
    "\n",
    "# Áp dụng PCA\n",
    "pca = PCA(n_components=2)\n",
    "reduced_data_pca = pca.fit_transform(images)\n",
    "\n",
    "# Hiển thị dữ liệu đã giảm chiều\n",
    "plt.scatter(reduced_data_pca[:, 0], reduced_data_pca[:, 1], c=labels)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "983223cb",
   "metadata": {},
   "source": [
    "## Giảm chiều dữ liệu bằng Convolutional Autoencoder (CAE)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "98a7dbc1",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn.functional as F\n",
    "\n",
    "# Tạo một CAE và huấn luyện nó\n",
    "cae = Autoencoder()\n",
    "# Bổ sung mã huấn luyện CAE ở đây\n",
    "\n",
    "# Sử dụng mô hình CAE để giảm chiều dữ liệu\n",
    "with torch.no_grad():\n",
    "    reduced_data_cae = cae.encoder(images).view(images.size(0), -1)\n",
    "\n",
    "# Hiển thị dữ liệu đã giảm chiều\n",
    "plt.scatter(reduced_data_cae[:, 0], reduced_data_cae[:, 1], c=labels)\n",
    "plt.colorbar()\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
